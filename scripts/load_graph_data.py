"""
åŠ è½½å›¾æ•°æ®é›† (YelpChi/Amazon)

ä»é¢„å¤„ç†çš„.npzæ–‡ä»¶ä¸­åŠ è½½å›¾æ•°æ®,ç”¨äºæ¨¡æ‹Ÿå›¾ç‰¹å¾æå–
"""
import sys
from pathlib import Path
import numpy as np
import polars as pl
from scipy.sparse import csr_matrix

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


class GraphDataLoader:
    """å›¾æ•°æ®åŠ è½½å™¨"""
    
    def __init__(self, dataset_name='yelp'):
        """
        åˆå§‹åŒ–å›¾æ•°æ®åŠ è½½å™¨
        
        Args:
            dataset_name: 'yelp' æˆ– 'amazon'
        """
        self.dataset_name = dataset_name
        # æ•°æ®åœ¨ data/processed/graph/ ç›®å½•ä¸‹
        self.data_dir = project_root / 'data' / 'processed' / 'graph' / dataset_name
        self.graph_data = None
        
    def load(self):
        """åŠ è½½å›¾æ•°æ®"""
        print(f"\n{'='*60}")
        print(f"åŠ è½½ {self.dataset_name.upper()} å›¾æ•°æ®é›†")
        print(f"{'='*60}")
        
        # å°è¯•åŠ è½½.npzæ–‡ä»¶ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä»åˆ†ç¦»æ–‡ä»¶åŠ è½½
        data_file = self.data_dir / f'{self.dataset_name}.npz'
        
        if data_file.exists():
            # ç›´æ¥åŠ è½½.npzæ–‡ä»¶
            print(f"\nğŸ“‚ åŠ è½½æ–‡ä»¶: {data_file}")
            data = np.load(str(data_file), allow_pickle=True)
            
            self.graph_data = {
                'features': data['features'],
                'labels': data['labels'],
                'adjacency': data['adjacency'],
            }
        else:
            # ä»åˆ†ç¦»æ–‡ä»¶åŠ è½½
            print(f"\nğŸ“‚ ä»åˆ†ç¦»æ–‡ä»¶åŠ è½½...")
            features_file = self.data_dir / 'features.npy'
            labels_file = self.data_dir / 'labels.npy'
            adj_file = self.data_dir / 'adj_matrix.npz'
            
            if not all([f.exists() for f in [features_file, labels_file, adj_file]]):
                raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.data_dir}")
            
            print(f"   åŠ è½½: {features_file.name}")
            features = np.load(str(features_file), allow_pickle=True)
            
            print(f"   åŠ è½½: {labels_file.name}")
            labels = np.load(str(labels_file), allow_pickle=True)
            
            print(f"   åŠ è½½: {adj_file.name}")
            adj_data = np.load(str(adj_file), allow_pickle=True)
            adjacency = csr_matrix(
                (adj_data['data'], adj_data['indices'], adj_data['indptr']),
                shape=adj_data['shape']
            )
            
            self.graph_data = {
                'features': features,
                'labels': labels,
                'adjacency': adjacency,
            }
        
        # è½¬æ¢é‚»æ¥çŸ©é˜µä¸ºç¨€ç–çŸ©é˜µ
        if not isinstance(self.graph_data['adjacency'], csr_matrix):
            self.graph_data['adjacency'] = csr_matrix(self.graph_data['adjacency'])
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        n_nodes = self.graph_data['features'].shape[0]
        n_features = self.graph_data['features'].shape[1]
        n_edges = self.graph_data['adjacency'].nnz
        n_fraud = np.sum(self.graph_data['labels'] == 1)
        fraud_rate = n_fraud / n_nodes * 100
        
        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"  èŠ‚ç‚¹æ•°é‡: {n_nodes:,}")
        print(f"  èŠ‚ç‚¹ç‰¹å¾ç»´åº¦: {n_features}")
        print(f"  è¾¹æ•°é‡: {n_edges:,}")
        print(f"  å¹³å‡åº¦: {n_edges / n_nodes:.2f}")
        print(f"  æ¬ºè¯ˆèŠ‚ç‚¹æ•°: {n_fraud:,}")
        print(f"  æ¬ºè¯ˆç‡: {fraud_rate:.2f}%")
        
        return self.graph_data
    
    def get_node_info(self, node_id):
        """è·å–èŠ‚ç‚¹ä¿¡æ¯"""
        if self.graph_data is None:
            raise ValueError("è¯·å…ˆè°ƒç”¨ load() æ–¹æ³•åŠ è½½æ•°æ®")
        
        if node_id >= self.graph_data['features'].shape[0]:
            return None
        
        # è·å–é‚»å±…èŠ‚ç‚¹
        adjacency = self.graph_data['adjacency']
        neighbors = adjacency[node_id].nonzero()[1]
        
        # ç»Ÿè®¡é‚»å±…ä¸­çš„æ¬ºè¯ˆèŠ‚ç‚¹
        neighbor_labels = self.graph_data['labels'][neighbors]
        n_fraud_neighbors = np.sum(neighbor_labels == 1)
        
        return {
            'node_id': node_id,
            'is_fraud': bool(self.graph_data['labels'][node_id] == 1),
            'features': self.graph_data['features'][node_id],
            'degree': len(neighbors),
            'fraud_neighbors': n_fraud_neighbors,
            'neighbor_fraud_rate': n_fraud_neighbors / len(neighbors) if len(neighbors) > 0 else 0.0
        }
    
    def compute_graph_features(self, node_id):
        """
        è®¡ç®—èŠ‚ç‚¹çš„å›¾ç‰¹å¾ (æ¨¡æ‹Ÿ15ç»´å›¾ç‰¹å¾)
        
        è¿™é‡Œä½¿ç”¨ç®€åŒ–çš„å›¾ç‰¹å¾è®¡ç®—,å®é™…åº”è¯¥è¿æ¥Neo4j
        """
        node_info = self.get_node_info(node_id)
        
        if node_info is None:
            # èŠ‚ç‚¹ä¸å­˜åœ¨,è¿”å›é›¶ç‰¹å¾
            return np.zeros(15)
        
        adjacency = self.graph_data['adjacency']
        neighbors = adjacency[node_id].nonzero()[1]
        
        # è®¡ç®—å›¾ç‰¹å¾
        features = []
        
        # 1. èŠ‚ç‚¹ç‰¹å¾ (5ç»´)
        features.append(node_info['fraud_neighbors'])  # æ¬ºè¯ˆé‚»å±…æ•°é‡
        features.append(node_info['neighbor_fraud_rate'])  # é‚»å±…æ¬ºè¯ˆç‡
        features.append(node_info['degree'])  # èŠ‚ç‚¹åº¦
        features.append(0.0)  # PageRank (ç®€åŒ–,ä½¿ç”¨0)
        
        # è®¡ç®—åˆ°æ¬ºè¯ˆèŠ‚ç‚¹çš„æœ€çŸ­è·ç¦» (é™åˆ¶2è·³)
        fraud_nodes = np.where(self.graph_data['labels'] == 1)[0]
        min_distance = 999
        if len(neighbors) > 0:
            # æ£€æŸ¥1è·³é‚»å±…
            if node_info['fraud_neighbors'] > 0:
                min_distance = 1
            else:
                # æ£€æŸ¥2è·³é‚»å±…
                for neighbor in neighbors[:10]:  # é™åˆ¶æ£€æŸ¥æ•°é‡
                    neighbor_neighbors = adjacency[neighbor].nonzero()[1]
                    if np.any(np.isin(neighbor_neighbors, fraud_nodes)):
                        min_distance = 2
                        break
        features.append(min_distance)
        
        # 2. å…³ç³»ç‰¹å¾ (7ç»´) - ç®€åŒ–è®¡ç®—
        # è¿™é‡Œä½¿ç”¨åº¦æ•°æ¥æ¨¡æ‹Ÿå…±äº«åº¦
        features.append(min(node_info['degree'], 10))  # è®¾å¤‡å…±äº«åº¦ (capped at 10)
        features.append(node_info['neighbor_fraud_rate'])  # è®¾å¤‡æ¬ºè¯ˆå æ¯”
        features.append(min(node_info['degree'], 8))  # IPå…±äº«åº¦
        features.append(node_info['neighbor_fraud_rate'] * 0.8)  # IPæ¬ºè¯ˆå æ¯”
        features.append(min(node_info['degree'], 5))  # åœ°å€å…±äº«åº¦
        features.append(0.5)  # æœ€å¼ºå…³è”æƒé‡
        features.append(node_info['neighbor_fraud_rate'])  # æ¬ºè¯ˆèšé›†ç³»æ•°
        
        # 3. å­å›¾ç‰¹å¾ (3ç»´)
        # è®¡ç®—å±€éƒ¨èšé›†ç³»æ•°
        if len(neighbors) > 1:
            neighbor_connections = 0
            for i, n1 in enumerate(neighbors[:10]):
                for n2 in neighbors[i+1:10]:
                    if adjacency[n1, n2] > 0:
                        neighbor_connections += 1
            max_connections = len(neighbors) * (len(neighbors) - 1) / 2
            clustering = neighbor_connections / max_connections if max_connections > 0 else 0
        else:
            clustering = 0
        
        features.append(clustering)  # å±€éƒ¨èšé›†ç³»æ•°
        features.append(node_info['neighbor_fraud_rate'])  # 1è·³é‚»å±…æ¬ºè¯ˆç‡
        features.append(1.0 if node_info['neighbor_fraud_rate'] > 0.5 else 0.0)  # æ˜¯å¦åœ¨æ¬ºè¯ˆç¤¾åŒº
        
        return np.array(features)
    
    def create_graph_feature_cache(self, output_file='graph_features_cache.npz'):
        """
        ä¸ºæ‰€æœ‰èŠ‚ç‚¹é¢„è®¡ç®—å›¾ç‰¹å¾å¹¶ç¼“å­˜
        
        è¿™æ¨¡æ‹Ÿäº†ç¦»çº¿é¢„è®¡ç®—+Redisç¼“å­˜çš„åœºæ™¯
        """
        print(f"\n{'='*60}")
        print("é¢„è®¡ç®—å›¾ç‰¹å¾ç¼“å­˜")
        print(f"{'='*60}")
        
        n_nodes = self.graph_data['features'].shape[0]
        graph_features_list = []
        
        print(f"\nè®¡ç®— {n_nodes:,} ä¸ªèŠ‚ç‚¹çš„å›¾ç‰¹å¾...")
        
        for i in range(n_nodes):
            if (i + 1) % 5000 == 0:
                print(f"  è¿›åº¦: {i+1:,}/{n_nodes:,} ({(i+1)/n_nodes*100:.1f}%)")
            
            graph_features = self.compute_graph_features(i)
            graph_features_list.append(graph_features)
        
        # è½¬æ¢ä¸ºæ•°ç»„
        graph_features_array = np.array(graph_features_list)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        cache_file = self.data_dir / output_file
        np.savez_compressed(
            cache_file,
            graph_features=graph_features_array,
            node_ids=np.arange(n_nodes)
        )
        
        print(f"\nâœ… å›¾ç‰¹å¾ç¼“å­˜å·²ä¿å­˜: {cache_file}")
        print(f"   å½¢çŠ¶: {graph_features_array.shape}")
        print(f"   å¤§å°: {cache_file.stat().st_size / 1024 / 1024:.2f} MB")
        
        return graph_features_array


def main():
    """ä¸»å‡½æ•°"""
    # åŠ è½½ YelpChi æ•°æ®é›†
    print("\n" + "="*60)
    print("å›¾æ•°æ®åŠ è½½ä¸ç‰¹å¾é¢„è®¡ç®—")
    print("="*60)
    
    # åŠ è½½ Yelp æ•°æ®
    yelp_loader = GraphDataLoader('yelp')
    yelp_data = yelp_loader.load()
    
    # æµ‹è¯•å•ä¸ªèŠ‚ç‚¹
    print(f"\n{'='*60}")
    print("æµ‹è¯•èŠ‚ç‚¹æŸ¥è¯¢")
    print(f"{'='*60}")
    
    test_node_id = 100
    node_info = yelp_loader.get_node_info(test_node_id)
    print(f"\nèŠ‚ç‚¹ {test_node_id} ä¿¡æ¯:")
    print(f"  æ˜¯å¦æ¬ºè¯ˆ: {node_info['is_fraud']}")
    print(f"  èŠ‚ç‚¹åº¦: {node_info['degree']}")
    print(f"  æ¬ºè¯ˆé‚»å±…æ•°: {node_info['fraud_neighbors']}")
    print(f"  é‚»å±…æ¬ºè¯ˆç‡: {node_info['neighbor_fraud_rate']:.2%}")
    
    # è®¡ç®—å›¾ç‰¹å¾
    graph_features = yelp_loader.compute_graph_features(test_node_id)
    print(f"\nå›¾ç‰¹å¾å‘é‡ ({len(graph_features)}ç»´):")
    print(f"  {graph_features}")
    
    # é¢„è®¡ç®—å¹¶ç¼“å­˜æ‰€æœ‰èŠ‚ç‚¹çš„å›¾ç‰¹å¾
    print(f"\n{'='*60}")
    choice = input("æ˜¯å¦é¢„è®¡ç®—æ‰€æœ‰èŠ‚ç‚¹çš„å›¾ç‰¹å¾? (y/n): ")
    if choice.lower() == 'y':
        yelp_loader.create_graph_feature_cache()
    
    print(f"\n{'='*60}")
    print("âœ¨ å®Œæˆ!")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()
