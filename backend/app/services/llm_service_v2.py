"""
LLM + Multi-Agent æœåŠ¡ (ReAct + Reflection å¢å¼ºç‰ˆ)

æ¶æ„è®¾è®¡:
1. CoordinatorAgent: åè°ƒå™¨,æ ¹æ®åˆæ­¥è¯„ä¼°å†³å®šæ‰§è¡Œè·¯å¾„
2. BehaviorAgent/GraphAgent/RuleAgent: ReAct æ¨¡å¼,å¸¦å·¥å…·è°ƒç”¨èƒ½åŠ›
3. ReflectionAgent: åæ€éªŒè¯,æ£€æŸ¥çŸ›ç›¾å’Œä¸åˆç†ä¹‹å¤„  
4. JudgeAgent: æœ€ç»ˆè£å†³

ç‰¹æ€§:
- å¹¶è¡Œæ‰§è¡Œ Behavior/Graph/Rule Agent (æ€§èƒ½ä¼˜åŒ–)
- æ¯ä¸ª Agent éƒ½æ”¯æŒ ReAct å¾ªç¯ (Thought â†’ Action â†’ Observation)
- åæ€æœºåˆ¶ç¡®ä¿å†³ç­–è´¨é‡
"""
from __future__ import annotations

import json
import asyncio
from typing import Any, Dict, List, Optional, Callable
from typing_extensions import TypedDict

from langgraph.graph import StateGraph, END
from openai import AsyncOpenAI

from app.core.config import settings
from app.core.logger import logger


# ===================== å·¥å…·å‡½æ•°å®šä¹‰ (Tool Functions) =====================

class AgentTools:
    """Agent å¯ç”¨çš„å·¥å…·é›†åˆ
    
    å½“å‰ç‰ˆæœ¬: å·¥å…·å‡½æ•°ä½¿ç”¨ pass å ä½,åç»­å¯ä»¥å®ç°çœŸå®é€»è¾‘
    """
    
    @staticmethod
    async def query_user_history(user_id: str, days: int = 30) -> Dict[str, Any]:
        """æŸ¥è¯¢ç”¨æˆ·å†å²äº¤æ˜“æ•°æ®
        
        Args:
            user_id: ç”¨æˆ·ID
            days: æŸ¥è¯¢æœ€è¿‘å¤šå°‘å¤©çš„æ•°æ®
            
        Returns:
            åŒ…å«ç”¨æˆ·å†å²äº¤æ˜“ç»Ÿè®¡çš„å­—å…¸
        """
        logger.debug(f"ğŸ”§ Toolè°ƒç”¨: query_user_history(user_id={user_id}, days={days})")
        # TODO: å®ç°çœŸå®çš„æ•°æ®åº“æŸ¥è¯¢
        pass
        
    @staticmethod
    async def query_device_reputation(device_id: str) -> Dict[str, Any]:
        """æŸ¥è¯¢è®¾å¤‡ä¿¡èª‰åˆ†å’Œå†å²è®°å½•
        
        Args:
            device_id: è®¾å¤‡ID
            
        Returns:
            è®¾å¤‡ä¿¡èª‰ä¿¡æ¯
        """
        logger.debug(f"ğŸ”§ Toolè°ƒç”¨: query_device_reputation(device_id={device_id})")
        # TODO: æŸ¥è¯¢è®¾å¤‡é»‘åå•/ç™½åå•
        pass
        
    @staticmethod
    async def query_ip_blacklist(ip_address: str) -> Dict[str, Any]:
        """æŸ¥è¯¢IPæ˜¯å¦åœ¨é»‘åå•ä¸­
        
        Args:
            ip_address: IPåœ°å€
            
        Returns:
            IPé£é™©ä¿¡æ¯
        """
        logger.debug(f"ğŸ”§ Toolè°ƒç”¨: query_ip_blacklist(ip_address={ip_address})")
        # TODO: æŸ¥è¯¢IPé»‘åå•æ•°æ®åº“
        pass
        
    @staticmethod
    async def query_merchant_info(merchant_id: str) -> Dict[str, Any]:
        """æŸ¥è¯¢å•†æˆ·ä¿¡æ¯
        
        Args:
            merchant_id: å•†æˆ·ID
            
        Returns:
            å•†æˆ·ä¿¡èª‰å’Œå†å²æ•°æ®
        """
        logger.debug(f"ğŸ”§ Toolè°ƒç”¨: query_merchant_info(merchant_id={merchant_id})")
        # TODO: æŸ¥è¯¢å•†æˆ·æ•°æ®åº“
        pass
        
    @staticmethod
    async def query_similar_cases(features: Dict[str, Any], top_k: int = 5) -> List[Dict[str, Any]]:
        """æŸ¥è¯¢ç›¸ä¼¼å†å²æ¡ˆä¾‹ (RAG)
        
        Args:
            features: å½“å‰äº¤æ˜“ç‰¹å¾
            top_k: è¿”å›æœ€ç›¸ä¼¼çš„Kä¸ªæ¡ˆä¾‹
            
        Returns:
            ç›¸ä¼¼æ¡ˆä¾‹åˆ—è¡¨
        """
        logger.debug(f"ğŸ”§ Toolè°ƒç”¨: query_similar_cases(top_k={top_k})")
        # TODO: å‘é‡æ£€ç´¢ (Qdrant/Milvus)
        pass
        
    @staticmethod
    async def calculate_velocity(user_id: str, time_window: int = 3600) -> Dict[str, Any]:
        """è®¡ç®—äº¤æ˜“é€Ÿç‡ (Velocity Check)
        
        Args:
            user_id: ç”¨æˆ·ID
            time_window: æ—¶é—´çª—å£(ç§’)
            
        Returns:
            äº¤æ˜“é€Ÿç‡ç»Ÿè®¡
        """
        logger.debug(f"ğŸ”§ Toolè°ƒç”¨: calculate_velocity(user_id={user_id}, time_window={time_window})")
        # TODO: æŸ¥è¯¢ Redis/æ—¶åºæ•°æ®åº“
        pass


# ===================== çŠ¶æ€å®šä¹‰ =====================

class FraudState(TypedDict, total=False):
    """LangGraph çŠ¶æ€ç±»å‹ (å¢å¼ºç‰ˆ)
    
    payload: é€å…¥ LLM çš„ä¸Šä¸‹æ–‡
    coordinator_decision: åè°ƒå™¨çš„è·¯ç”±å†³ç­–
    behavior: è¡Œä¸ºåˆ†æ Agent è¾“å‡º
    graph: å›¾å…³ç³»åˆ†æ Agent è¾“å‡º
    rule: è§„åˆ™ä¸åˆè§„ Agent è¾“å‡º
    reflection: åæ€ Agent çš„éªŒè¯ç»“æœ
    llm_output: è£å†³ Agent æœ€ç»ˆè¾“å‡º
    """
    
    payload: Dict[str, Any]
    coordinator_decision: Dict[str, Any]
    behavior: Dict[str, Any]
    graph: Dict[str, Any]
    rule: Dict[str, Any]
    reflection: Dict[str, Any]
    llm_output: Dict[str, Any]


# ===================== Kimi å®¢æˆ·ç«¯ =====================

class KimiClient:
    """Kimi 2 API å®¢æˆ·ç«¯å°è£… (å¤ç”¨åŸæœ‰å®ç°)"""
    
    def __init__(self, api_key: str, base_url: str, model: str) -> None:
        self.api_key = api_key
        self.base_url = base_url.rstrip("/")
        self.model = model
        self._client = AsyncOpenAI(api_key=self.api_key, base_url=self.base_url)

    async def chat(self, messages: List[Dict[str, str]], timeout: float = 10.0) -> str:
        """è°ƒç”¨ Kimi Chat æ¥å£"""
        if not self.api_key:
            raise RuntimeError("KIMI_API_KEY æœªé…ç½®, æ— æ³•è°ƒç”¨ LLM")

        try:
            resp = await self._client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.2,
                stream=False,
            )
        except Exception as e:
            logger.error(f"è°ƒç”¨ Kimi(OpenAI SDK) å¤±è´¥: {e}")
            raise

        try:
            return resp.choices[0].message.content or ""
        except Exception as e:
            logger.error(f"è§£æ Kimi å“åº”å¤±è´¥: {e}")
            raise


# ===================== ä¸»æœåŠ¡ç±» =====================

class LlmAgentService:
    """LLM Multi-Agent æœåŠ¡ (ReAct + Reflection æ¶æ„)
    
    å·¥ä½œæµ:
    1. CoordinatorAgent: è¯„ä¼°é£é™©,å†³å®šæ‰§è¡Œè·¯å¾„
    2. å¹¶è¡Œæ‰§è¡Œ Behavior/Graph/Rule Agent (ReAct æ¨¡å¼)
    3. ReflectionAgent: åæ€éªŒè¯
    4. JudgeAgent: æœ€ç»ˆè£å†³
    """

    def __init__(self) -> None:
        if not settings.KIMI_API_KEY:
            logger.warning("KIMI_API_KEY æœªé…ç½®, LLM åŠŸèƒ½å°†ä¸å¯ç”¨")
        self.client = KimiClient(
            api_key=settings.KIMI_API_KEY,
            base_url=settings.KIMI_BASE_URL,
            model=settings.KIMI_MODEL,
        )
        self.tools = AgentTools()
        
        # æ„å»º LangGraph å·¥ä½œæµ
        graph = StateGraph(FraudState)
        
        # æ·»åŠ èŠ‚ç‚¹
        graph.add_node("coordinator_agent", self._coordinator_agent_node)
        graph.add_node("parallel_agents", self._parallel_agents_node)
        graph.add_node("reflection_agent", self._reflection_agent_node)
        graph.add_node("judge_agent", self._judge_agent_node)
        
        # è®¾ç½®æµç¨‹
        graph.set_entry_point("coordinator_agent")
        graph.add_edge("coordinator_agent", "parallel_agents")
        graph.add_edge("parallel_agents", "reflection_agent")
        graph.add_edge("reflection_agent", "judge_agent")
        graph.add_edge("judge_agent", END)
        
        self._graph = graph.compile()

    # ===================== Agent èŠ‚ç‚¹å®ç° =====================
    
    async def _coordinator_agent_node(self, state: FraudState) -> FraudState:
        """åè°ƒå™¨ Agent: è¯„ä¼°é£é™©çº§åˆ«,å†³å®šåç»­æ‰§è¡Œè·¯å¾„
        
        ç­–ç•¥:
        - ä½é£é™© (<0.3): åªæ‰§è¡Œ RuleAgent
        - ä¸­é£é™© (0.3-0.7): æ‰§è¡Œå…¨éƒ¨ 3 ä¸ª Agent
        - é«˜é£é™© (>0.7): æ‰§è¡Œå…¨éƒ¨ + é¢å¤–å·¥å…·è°ƒç”¨
        """
        payload = state["payload"]
        logger.info("\n" + "#"*80)
        logger.info("ğŸ§­ CoordinatorAgent å¼€å§‹åè°ƒ...")
        logger.info("#"*80)
        
        if not settings.KIMI_API_KEY:
            state["coordinator_decision"] = {
                "execution_mode": "standard",
                "agents_to_run": ["behavior", "graph", "rule"],
                "reason": "LLMæœªå¯ç”¨,ä½¿ç”¨é»˜è®¤ç­–ç•¥"
            }
            return state
        
        # è·å– fast_detect çš„åˆæ­¥è¯„åˆ†
        fast_score = payload.get("fast_result", {}).get("fraud_score", 0.5)
        
        # åŠ¨æ€è·¯ç”±å†³ç­–
        if fast_score < 0.3:
            execution_mode = "fast"
            agents_to_run = ["rule"]
            reason = f"ä½é£é™©äº¤æ˜“(score={fast_score:.2f}),ä»…éœ€è§„åˆ™éªŒè¯"
        elif fast_score > 0.7:
            execution_mode = "deep"
            agents_to_run = ["behavior", "graph", "rule"]
            reason = f"é«˜é£é™©äº¤æ˜“(score={fast_score:.2f}),å¯åŠ¨æ·±åº¦åˆ†æ"
        else:
            execution_mode = "standard"
            agents_to_run = ["behavior", "graph", "rule"]
            reason = f"ä¸­é£é™©äº¤æ˜“(score={fast_score:.2f}),æ‰§è¡Œæ ‡å‡†æµç¨‹"
        
        decision = {
            "execution_mode": execution_mode,
            "agents_to_run": agents_to_run,
            "fast_score": fast_score,
            "reason": reason
        }
        
        logger.info(f"âœ… åè°ƒå†³ç­–: {decision}")
        state["coordinator_decision"] = decision
        return state
    
    async def _parallel_agents_node(self, state: FraudState) -> FraudState:
        """å¹¶è¡Œæ‰§è¡Œ Behavior/Graph/Rule Agent"""
        logger.info("\n" + "="*80)
        logger.info("ğŸš€ å¯åŠ¨å¹¶è¡Œ Agent æ‰§è¡Œ...")
        logger.info("="*80)
        
        decision = state.get("coordinator_decision", {})
        agents_to_run = decision.get("agents_to_run", ["behavior", "graph", "rule"])
        
        # åˆ›å»ºå¹¶è¡Œä»»åŠ¡
        tasks = []
        if "behavior" in agents_to_run:
            tasks.append(self._behavior_agent_react(state))
        if "graph" in agents_to_run:
            tasks.append(self._graph_agent_react(state))
        if "rule" in agents_to_run:
            tasks.append(self._rule_agent_react(state))
        
        # å¹¶è¡Œæ‰§è¡Œ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        for i, agent_name in enumerate(["behavior", "graph", "rule"]):
            if agent_name not in agents_to_run:
                state[agent_name] = {"skipped": True}
            elif isinstance(results[agents_to_run.index(agent_name)], Exception):
                logger.error(f"âŒ {agent_name}Agent æ‰§è¡Œå¤±è´¥: {results[i]}")
                state[agent_name] = {"error": str(results[i])}
            else:
                state[agent_name] = results[agents_to_run.index(agent_name)]
        
        logger.info("âœ… å¹¶è¡Œ Agent æ‰§è¡Œå®Œæˆ")
        return state
    
    async def _behavior_agent_react(self, state: FraudState) -> Dict[str, Any]:
        """BehaviorAgent (ReAct æ¨¡å¼)
        
        ReAct å¾ªç¯:
        1. Thought: æˆ‘éœ€è¦åˆ†æç”¨æˆ·è¡Œä¸ºæ¨¡å¼
        2. Action: è°ƒç”¨ query_user_history å·¥å…·
        3. Observation: ç”¨æˆ·æœ€è¿‘30å¤©å¹³å‡äº¤æ˜“é¢500å…ƒ
        4. Thought: å½“å‰äº¤æ˜“12888å…ƒ,æ˜¯å‡å€¼çš„25å€,å¼‚å¸¸
        5. æœ€ç»ˆè¾“å‡ºé£é™©ç»“è®º
        """
        payload = state["payload"]
        logger.info("="*60)
        logger.info("ğŸ¤– BehaviorAgent (ReAct) å¼€å§‹åˆ†æ...")
        
        if not settings.KIMI_API_KEY:
            return {
                "behavior_risk_level": "medium",
                "behavior_reasons": ["LLMæœªå¯ç”¨"],
                "tool_calls": []
            }
        
        # ReAct Prompt: æŒ‡å¯¼ LLM è¿›è¡Œæ¨ç†+å·¥å…·è°ƒç”¨
        system_prompt = """ä½ æ˜¯é‡‘èåæ¬ºè¯ˆç³»ç»Ÿä¸­çš„'è¡Œä¸ºæ¨¡å¼åˆ†æ'ä¸“å®¶ã€‚

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥è¾…åŠ©åˆ†æ:
- query_user_history(user_id, days=30): æŸ¥è¯¢ç”¨æˆ·å†å²äº¤æ˜“æ•°æ®
- calculate_velocity(user_id, time_window=3600): è®¡ç®—äº¤æ˜“é€Ÿç‡

è¯·æŒ‰ç…§ ReAct æ¨¡å¼è¿›è¡Œåˆ†æ:
1. Thought: æ€è€ƒéœ€è¦ä»€ä¹ˆä¿¡æ¯
2. Action: å†³å®šè°ƒç”¨å“ªä¸ªå·¥å…· (å¦‚æœéœ€è¦)
3. Observation: å·¥å…·è¿”å›çš„ç»“æœ
4. (é‡å¤1-3,ç›´åˆ°æœ‰è¶³å¤Ÿä¿¡æ¯)
5. Final Answer: ç»™å‡ºæœ€ç»ˆé£é™©åˆ¤æ–­

æœ€ç»ˆè¾“å‡º JSON æ ¼å¼:
{
  "behavior_risk_level": "high|medium|low",
  "behavior_reasons": ["åŸå› 1", "åŸå› 2"],
  "thoughts": ["æ€è€ƒè¿‡ç¨‹1", "æ€è€ƒè¿‡ç¨‹2"],
  "tool_calls": ["ä½¿ç”¨çš„å·¥å…·åç§°"]
}
"""
        
        user_prompt = f"""åˆ†æä»¥ä¸‹äº¤æ˜“çš„è¡Œä¸ºé£é™©:\n{json.dumps(payload, ensure_ascii=False, indent=2)}

è¯·æŒ‰ç…§ ReAct æ¨¡å¼è¿›è¡Œæ¨ç†,æ˜ç¡®è¯´æ˜ä½ çš„æ€è€ƒè¿‡ç¨‹å’Œå·¥å…·è°ƒç”¨ã€‚"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        try:
            content = await self.client.chat(messages)
            logger.info(f"âœ… BehaviorAgent åŸå§‹å“åº”: {content}")
            
            # è§£æ JSON (å®¹é”™å¤„ç†)
            try:
                result = json.loads(content)
            except json.JSONDecodeError:
                # å¦‚æœä¸æ˜¯çº¯ JSON,å°è¯•æå–
                result = {
                    "behavior_risk_level": "medium",
                    "behavior_reasons": ["è§£æå¤±è´¥,ä½¿ç”¨é»˜è®¤"],
                    "thoughts": [content[:200]],
                    "tool_calls": []
                }
            
            logger.info(f"âœ… BehaviorAgent è§£æç»“æœ: {result}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ BehaviorAgent å¤±è´¥: {e}")
            return {
                "behavior_risk_level": "medium",
                "behavior_reasons": [f"æ‰§è¡Œå¼‚å¸¸: {str(e)}"],
                "tool_calls": []
            }
    
    async def _graph_agent_react(self, state: FraudState) -> Dict[str, Any]:
        """GraphAgent (ReAct æ¨¡å¼)"""
        payload = state["payload"]
        logger.info("="*60)
        logger.info("ğŸ¤– GraphAgent (ReAct) å¼€å§‹åˆ†æ...")
        
        if not settings.KIMI_API_KEY:
            return {
                "graph_risk_level": "medium",
                "graph_reasons": ["LLMæœªå¯ç”¨"],
                "tool_calls": []
            }
        
        system_prompt = """ä½ æ˜¯é‡‘èåæ¬ºè¯ˆç³»ç»Ÿä¸­çš„'å›¾å…³ç³»é£é™©'ä¸“å®¶ã€‚

å¯ç”¨å·¥å…·:
- query_device_reputation(device_id): æŸ¥è¯¢è®¾å¤‡ä¿¡èª‰åˆ†
- query_ip_blacklist(ip_address): æŸ¥è¯¢IPé»‘åå•
- query_similar_cases(features, top_k=5): æŸ¥è¯¢ç›¸ä¼¼å†å²æ¡ˆä¾‹

è¯·ä½¿ç”¨ ReAct æ¨¡å¼åˆ†æå›¾å…³ç³»é£é™©,è¾“å‡º JSON:
{
  "graph_risk_level": "high|medium|low",
  "graph_reasons": ["åŸå› 1", "åŸå› 2"],
  "thoughts": ["æ€è€ƒè¿‡ç¨‹"],
  "tool_calls": ["ä½¿ç”¨çš„å·¥å…·"]
}
"""
        
        user_prompt = f"""åˆ†æå›¾å…³ç³»é£é™©:\n{json.dumps(payload, ensure_ascii=False, indent=2)}"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        try:
            content = await self.client.chat(messages)
            logger.info(f"âœ… GraphAgent åŸå§‹å“åº”: {content}")
            
            try:
                result = json.loads(content)
            except json.JSONDecodeError:
                result = {
                    "graph_risk_level": "medium",
                    "graph_reasons": ["è§£æå¤±è´¥"],
                    "thoughts": [content[:200]],
                    "tool_calls": []
                }
            
            logger.info(f"âœ… GraphAgent è§£æç»“æœ: {result}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ GraphAgent å¤±è´¥: {e}")
            return {
                "graph_risk_level": "medium",
                "graph_reasons": [f"æ‰§è¡Œå¼‚å¸¸: {str(e)}"],
                "tool_calls": []
            }
    
    async def _rule_agent_react(self, state: FraudState) -> Dict[str, Any]:
        """RuleAgent (ReAct æ¨¡å¼)"""
        payload = state["payload"]
        logger.info("="*60)
        logger.info("ğŸ¤– RuleAgent (ReAct) å¼€å§‹åˆ†æ...")
        
        if not settings.KIMI_API_KEY:
            return {
                "rule_risk_level": "medium",
                "rule_reasons": ["LLMæœªå¯ç”¨"],
                "tool_calls": []
            }
        
        system_prompt = """ä½ æ˜¯é‡‘èåæ¬ºè¯ˆç³»ç»Ÿä¸­çš„'è§„åˆ™ä¸åˆè§„'ä¸“å®¶ã€‚

å¯ç”¨å·¥å…·:
- query_merchant_info(merchant_id): æŸ¥è¯¢å•†æˆ·ä¿¡æ¯

è¯·ä½¿ç”¨ ReAct æ¨¡å¼åˆ†æè§„åˆ™åˆè§„æ€§,è¾“å‡º JSON:
{
  "rule_risk_level": "high|medium|low",
  "rule_reasons": ["åŸå› 1", "åŸå› 2"],
  "thoughts": ["æ€è€ƒè¿‡ç¨‹"],
  "tool_calls": ["ä½¿ç”¨çš„å·¥å…·"]
}
"""
        
        user_prompt = f"""åˆ†æè§„åˆ™é£é™©:\n{json.dumps(payload, ensure_ascii=False, indent=2)}"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        try:
            content = await self.client.chat(messages)
            logger.info(f"âœ… RuleAgent åŸå§‹å“åº”: {content}")
            
            try:
                result = json.loads(content)
            except json.JSONDecodeError:
                result = {
                    "rule_risk_level": "medium",
                    "rule_reasons": ["è§£æå¤±è´¥"],
                    "thoughts": [content[:200]],
                    "tool_calls": []
                }
            
            logger.info(f"âœ… RuleAgent è§£æç»“æœ: {result}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ RuleAgent å¤±è´¥: {e}")
            return {
                "rule_risk_level": "medium",
                "rule_reasons": [f"æ‰§è¡Œå¼‚å¸¸: {str(e)}"],
                "tool_calls": []
            }
    
    async def _reflection_agent_node(self, state: FraudState) -> FraudState:
        """åæ€ Agent: æ£€æŸ¥å‰é¢ Agent çš„ç»“è®ºæ˜¯å¦ä¸€è‡´ã€åˆç†
        
        åŠŸèƒ½:
        1. æ£€æŸ¥ Behavior/Graph/Rule ä¸‰ä¸ª Agent çš„ç»“è®ºæ˜¯å¦çŸ›ç›¾
        2. è´¨ç–‘ä¸åˆç†çš„æ¨ç†
        3. å¦‚æœå‘ç°ä¸¥é‡çŸ›ç›¾,å¯ä»¥è¦æ±‚é‡æ–°åˆ†æ
        """
        logger.info("\n" + "="*80)
        logger.info("ğŸ” ReflectionAgent å¼€å§‹åæ€éªŒè¯...")
        logger.info("="*80)
        
        if not settings.KIMI_API_KEY:
            state["reflection"] = {
                "is_consistent": True,
                "concerns": [],
                "recommendation": "proceed"
            }
            return state
        
        # æ”¶é›†ä¸‰ä¸ª Agent çš„ç»“è®º
        behavior = state.get("behavior", {})
        graph = state.get("graph", {})
        rule = state.get("rule", {})
        
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªåæ€ä¸éªŒè¯ä¸“å®¶,è´Ÿè´£æ£€æŸ¥å…¶ä»– Agent çš„åˆ†æç»“è®ºã€‚

ä½ çš„ä»»åŠ¡:
1. æ£€æŸ¥ Behavior/Graph/Rule ä¸‰ä¸ª Agent çš„ç»“è®ºæ˜¯å¦ä¸€è‡´
2. è¯†åˆ«é€»è¾‘çŸ›ç›¾ (ä¾‹å¦‚: Behaviorè¯´ä½é£é™©,ä½†Graphè¯´é«˜é£é™©)
3. è´¨ç–‘ä¸åˆç†çš„æ¨ç†
4. ç»™å‡ºæ”¹è¿›å»ºè®®

è¾“å‡º JSON æ ¼å¼:
{
  "is_consistent": true/false,
  "concerns": ["å‘ç°çš„é—®é¢˜1", "é—®é¢˜2"],
  "recommendation": "proceed|re_analyze|escalate"
}
"""
        
        user_prompt = f"""è¯·æ£€æŸ¥ä»¥ä¸‹ä¸‰ä¸ª Agent çš„åˆ†æç»“è®º:

BehaviorAgent: {json.dumps(behavior, ensure_ascii=False)}

GraphAgent: {json.dumps(graph, ensure_ascii=False)}

RuleAgent: {json.dumps(rule, ensure_ascii=False)}

è¯·æŒ‡å‡ºä»»ä½•çŸ›ç›¾æˆ–ä¸åˆç†ä¹‹å¤„ã€‚"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        try:
            content = await self.client.chat(messages)
            logger.info(f"âœ… ReflectionAgent åŸå§‹å“åº”: {content}")
            
            try:
                reflection = json.loads(content)
            except json.JSONDecodeError:
                reflection = {
                    "is_consistent": True,
                    "concerns": ["è§£æå¤±è´¥,é»˜è®¤é€šè¿‡"],
                    "recommendation": "proceed"
                }
            
            logger.info(f"âœ… ReflectionAgent éªŒè¯ç»“æœ: {reflection}")
            
            # å¦‚æœå‘ç°ä¸¥é‡çŸ›ç›¾,è®°å½•è­¦å‘Š
            if not reflection.get("is_consistent", True):
                logger.warning(f"âš ï¸ ReflectionAgent å‘ç°çŸ›ç›¾: {reflection.get('concerns')}")
            
            state["reflection"] = reflection
            return state
            
        except Exception as e:
            logger.error(f"âŒ ReflectionAgent å¤±è´¥: {e}")
            state["reflection"] = {
                "is_consistent": True,
                "concerns": [f"åæ€å¤±è´¥: {str(e)}"],
                "recommendation": "proceed"
            }
            return state
    
    async def _judge_agent_node(self, state: FraudState) -> FraudState:
        """è£å†³ Agent: ç»¼åˆæ‰€æœ‰ Agent çš„ç»“è®º,ç»™å‡ºæœ€ç»ˆå†³ç­–"""
        logger.info("\n" + "="*80)
        logger.info("âš–ï¸ JudgeAgent å¼€å§‹æœ€ç»ˆè£å†³...")
        logger.info("="*80)
        
        if not settings.KIMI_API_KEY:
            state["llm_output"] = {
                "llm_decision": "review",
                "llm_risk_score": 0.5,
                "llm_confidence": 0.0,
                "llm_reasons": ["LLMæœªå¯ç”¨"],
                "llm_explanation": "LLMæœªå¯ç”¨,æ— æ³•ç»™å‡ºè¯¦ç»†åˆ†æ"
            }
            return state
        
        # æ”¶é›†æ‰€æœ‰ä¿¡æ¯
        combined = {
            "coordinator": state.get("coordinator_decision", {}),
            "behavior": state.get("behavior", {}),
            "graph": state.get("graph", {}),
            "rule": state.get("rule", {}),
            "reflection": state.get("reflection", {}),
            "fast_result": state["payload"].get("fast_result", {})
        }
        
        system_prompt = """ä½ æ˜¯é‡‘èåæ¬ºè¯ˆç³»ç»Ÿçš„æœ€ç»ˆè£åˆ¤ã€‚

ä½ éœ€è¦ç»¼åˆä»¥ä¸‹ä¿¡æ¯åšå‡ºæœ€ç»ˆå†³ç­–:
1. å¿«é€Ÿæ£€æµ‹æ¨¡å—çš„åˆæ­¥è¯„åˆ†
2. Behavior/Graph/Rule ä¸‰ä¸ªä¸“å®¶ Agent çš„åˆ†æ
3. ReflectionAgent çš„éªŒè¯ç»“æœ

è¾“å‡º JSON:
{
  "llm_decision": "accept|review|reject",
  "llm_risk_score": 0.0-1.0,
  "llm_confidence": 0.0-1.0,
  "llm_reasons": ["ç†ç”±1", "ç†ç”±2"],
  "llm_explanation": "è¯¦ç»†è§£é‡Š"
}
"""
        
        user_prompt = f"""ç»¼åˆä»¥ä¸‹ä¿¡æ¯åšå‡ºæœ€ç»ˆè£å†³:\n\n{json.dumps(combined, ensure_ascii=False, indent=2)}"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        try:
            content = await self.client.chat(messages)
            logger.info(f"âœ… JudgeAgent åŸå§‹å“åº”: {content}")
            
            try:
                llm_output = json.loads(content)
            except json.JSONDecodeError:
                llm_output = {
                    "llm_decision": "review",
                    "llm_risk_score": 0.5,
                    "llm_confidence": 0.3,
                    "llm_reasons": ["JSONè§£æå¤±è´¥"],
                    "llm_explanation": content[:500]
                }
            
            # å°†è£å†³ç»“æœä¹Ÿçº³å…¥å¿«ç…§,ç”¨äºåç»­å®¡è®¡
            combined["judge"] = llm_output
            
            # åœ¨ llm_output ä¸­é™„å¸¦å®Œæ•´ agents å¿«ç…§
            enriched_output = {
                **llm_output,
                "agents_snapshot": combined,
            }
            
            logger.info(f"âœ… JudgeAgent æœ€ç»ˆè£å†³: {enriched_output}")
            state["llm_output"] = enriched_output
            
            logger.info("\n" + "#"*80)
            logger.info("ğŸ¯ LLM+Agent å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
            logger.info(f"æœ€ç»ˆå†³ç­–: {enriched_output.get('llm_decision')}, é£é™©åˆ†æ•°: {enriched_output.get('llm_risk_score')}")
            logger.info("#"*80 + "\n")
            
            return state
            
        except Exception as e:
            logger.error(f"âŒ JudgeAgent å¤±è´¥: {e}")
            state["llm_output"] = {
                "llm_decision": "review",
                "llm_risk_score": 0.5,
                "llm_confidence": 0.0,
                "llm_reasons": [f"è£å†³å¤±è´¥: {str(e)}"],
                "llm_explanation": "ç³»ç»Ÿå¼‚å¸¸,å»ºè®®äººå·¥å®¡æ ¸"
            }
            return state
    
    # ===================== å…¬å¼€æ¥å£ =====================
    
    async def analyze_transaction(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå•ç¬”äº¤æ˜“ (å…¬å¼€æ¥å£)
        
        Args:
            payload: åŒ…å«äº¤æ˜“æ•°æ®å’Œ fast_detect ç»“æœçš„å­—å…¸
            
        Returns:
            LLM åˆ†æç»“æœ
        """
        logger.info("\n" + "#"*80)
        logger.info("ğŸš€ å¯åŠ¨ LLM+MultiAgent (ReAct+Reflection) å·¥ä½œæµ")
        logger.info("#"*80)
        logger.debug(f"åˆå§‹ payload: {payload}")
        
        # è°ƒç”¨ LangGraph
        result_state = await self._graph.ainvoke({"payload": payload})
        
        logger.info("\n" + "#"*80)
        logger.info("ğŸ¯ å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
        logger.info(f"æœ€ç»ˆè¾“å‡º: {result_state['llm_output']}")
        logger.info("#"*80 + "\n")
        
        return result_state["llm_output"]


# ===================== å…¨å±€å•ä¾‹ =====================

# å…¨å±€ LLM Agent æœåŠ¡å®ä¾‹ (ReAct + Reflection å¢å¼ºç‰ˆ)
llm_agent_service = LlmAgentService()
