"""
LLM + Agent æœåŠ¡å°è£…

å½“å‰é˜¶æ®µç›®æ ‡:
- æä¾›ç»Ÿä¸€çš„ Kimi2 å®¢æˆ·ç«¯å°è£…
- æä¾›ä¸€ä¸ªåŸºç¡€çš„ LLM åˆ†ææ¥å£, åç»­å¯å¹³æ»‘è¿ç§»åˆ° LangGraph å¤š Agent å·¥ä½œæµ
"""
from __future__ import annotations

import json
from typing import Any, Dict, List, Optional, TypedDict

import httpx
from langgraph.graph import StateGraph, END
from openai import AsyncOpenAI

from app.core.config import settings
from app.core.logger import logger


class FraudState(TypedDict, total=False):
    """LangGraph çŠ¶æ€ç±»å‹

    payload: é€å…¥ LLM çš„ä¸Šä¸‹æ–‡
    behavior: è¡Œä¸ºåˆ†æ Agent è¾“å‡º
    graph: å›¾å…³ç³»åˆ†æ Agent è¾“å‡º
    rule: è§„åˆ™ä¸åˆè§„ Agent è¾“å‡º
    llm_output: è£å†³ Agent æœ€ç»ˆè¾“å‡º
    """

    payload: Dict[str, Any]
    behavior: Dict[str, Any]
    graph: Dict[str, Any]
    rule: Dict[str, Any]
    llm_output: Dict[str, Any]


class KimiClient:
    """Kimi 2 API å®¢æˆ·ç«¯å°è£…

    ä½¿ç”¨ OpenAI å…¼å®¹ SDK è°ƒç”¨ Kimi çš„ Chat Completions æ¥å£ã€‚
    """

    def __init__(self, api_key: str, base_url: str, model: str) -> None:
        self.api_key = api_key
        self.base_url = base_url.rstrip("/")
        self.model = model
        # ä½¿ç”¨å®˜æ–¹ AsyncOpenAI å®¢æˆ·ç«¯, å…¼å®¹ Moonshot/Kimi æ¥å£
        self._client = AsyncOpenAI(api_key=self.api_key, base_url=self.base_url)

    async def chat(self, messages: List[Dict[str, str]], timeout: float = 10.0) -> str:
        """è°ƒç”¨ Kimi Chat æ¥å£, è¿”å› assistant çš„æ–‡æœ¬å†…å®¹ã€‚

        Args:
            messages: OpenAI é£æ ¼çš„å¯¹è¯åˆ—è¡¨, æ¯é¡¹åŒ…å« role/content
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ç§’ (ç›®å‰ç”± HTTP å®¢æˆ·ç«¯æ§åˆ¶, OpenAI SDK å†…ç½®)
        """
        if not self.api_key:
            raise RuntimeError("KIMI_API_KEY æœªé…ç½®, æ— æ³•è°ƒç”¨ LLM")

        try:
            resp = await self._client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.2,
                stream=False,
            )
        except Exception as e:  # noqa: BLE001
            logger.error(f"è°ƒç”¨ Kimi(OpenAI SDK) å¤±è´¥: {e}")
            raise

        try:
            # æ–°ç‰ˆ SDK è¿”å›å¯¹è±¡, ç›´æ¥ä» choices è¯»å–å†…å®¹
            return resp.choices[0].message.content or ""
        except Exception as e:  # noqa: BLE001
            logger.error(f"è§£æ Kimi å“åº”å¤±è´¥: {e}; åŸå§‹å“åº”å¯¹è±¡: {resp}")
            raise


class LlmAgentService:
    """LLM Agent æœåŠ¡

    åŸºäº LangGraph çš„å¤š Agent å·¥ä½œæµ:
    - BehaviorAgent: è¡Œä¸ºæ¨¡å¼åˆ†æ
    - GraphAgent: å›¾å…³ç³»é£é™©åˆ†æ
    - RuleAgent: è§„åˆ™ä¸åˆè§„åˆ†æ
    - JudgeAgent: ç»¼åˆè£å†³ä¸è§£é‡Š
    """

    def __init__(self) -> None:
        if not settings.KIMI_API_KEY:
            logger.warning("KIMI_API_KEY æœªé…ç½®, LLM åŠŸèƒ½å°†ä¸å¯ç”¨")
        self.client = KimiClient(
            api_key=settings.KIMI_API_KEY,
            base_url=settings.KIMI_BASE_URL,
            model=settings.KIMI_MODEL,
        )

        # æ„å»º LangGraph: å¤š Agent ä¸²è”å·¥ä½œæµ
        graph = StateGraph(FraudState)
        graph.add_node("behavior_agent", self._behavior_agent_node)
        graph.add_node("graph_agent", self._graph_agent_node)
        graph.add_node("rule_agent", self._rule_agent_node)
        graph.add_node("judge_agent", self._judge_agent_node)

        graph.set_entry_point("behavior_agent")
        graph.add_edge("behavior_agent", "graph_agent")
        graph.add_edge("graph_agent", "rule_agent")
        graph.add_edge("rule_agent", "judge_agent")
        graph.add_edge("judge_agent", END)

        self._graph = graph.compile()

    async def _behavior_agent_node(self, state: FraudState) -> FraudState:
        """è¡Œä¸ºæ¨¡å¼åˆ†æ Agent èŠ‚ç‚¹"""
        payload = state["payload"]
        logger.info("="*60)
        logger.info("ğŸ¤– BehaviorAgent å¼€å§‹åˆ†æ...")
        logger.debug(f"è¾“å…¥ payload: {payload}")
    
        if not settings.KIMI_API_KEY:
            state["behavior"] = {
                "behavior_risk_level": "medium",
                "behavior_reasons": ["LLM æœªå¯ç”¨, ä½¿ç”¨é»˜è®¤è¡Œä¸ºåˆ†æç»“æœ"],
            }
            logger.warning("BehaviorAgent: KIMI_API_KEY æœªé…ç½®, ä½¿ç”¨é»˜è®¤ç»“æœ")
            return state
    
        system_prompt = (
            "ä½ æ˜¯é‡‘èåæ¬ºè¯ˆç³»ç»Ÿä¸­çš„'è¡Œä¸ºæ¨¡å¼åˆ†æ'ä¸“å®¶, "
            "è´Ÿè´£ä»ç”¨æˆ·è¡Œä¸ºå’Œäº¤æ˜“æ¨¡å¼è§’åº¦è¯„ä¼°é£é™©ã€‚"
        )
        user_prompt = (
            "ä¸‹é¢æ˜¯ä¸å½“å‰äº¤æ˜“ç›¸å…³çš„ JSON æ•°æ®:\n\n"
            f"{json.dumps(payload, ensure_ascii=False)}\n\n"
            "è¯·åªä»'ç”¨æˆ·è¡Œä¸ºå’Œäº¤æ˜“æ¨¡å¼'çš„è§’åº¦è¿›è¡Œåˆ†æ, ç»™å‡ºè¡Œä¸ºé£é™©ç­‰çº§å’Œç®€è¦ç†ç”±ã€‚\n"
            "ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡º, ä¸è¦åŒ…å«å¤šä½™æ–‡å­—:\n"
            "{\n"
            '  "behavior_risk_level": "high|medium|low",\n'
            '  "behavior_reasons": ["åŸå› 1", "åŸå› 2"]\n'
            "}"
        )
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]
    
        logger.info(f"BehaviorAgent Prompt (user): {user_prompt[:200]}...")
            
        try:
            content = await self.client.chat(messages)
            logger.info(f"âœ… BehaviorAgent åŸå§‹å“åº”: {content}")
                
            parsed = json.loads(content)
            behavior = {
                "behavior_risk_level": str(parsed.get("behavior_risk_level", "medium")),
                "behavior_reasons": parsed.get("behavior_reasons", []) or [],
            }
            logger.info(f"âœ… BehaviorAgent è§£æç»“æœ: {behavior}")
        except Exception as e:  # noqa: BLE001
            logger.error(f"âŒ BehaviorAgent è°ƒç”¨æˆ–è§£æå¤±è´¥: {e}")
            behavior = {
                "behavior_risk_level": "medium",
                "behavior_reasons": ["BehaviorAgent è¾“å‡ºå¼‚å¸¸, ä½¿ç”¨é»˜è®¤ç»“æœ"],
            }
            logger.warning(f"BehaviorAgent ä½¿ç”¨å…œåº•ç»“æœ: {behavior}")
    
        state["behavior"] = behavior
        logger.info("="*60)
        return state
    
    async def _graph_agent_node(self, state: FraudState) -> FraudState:
        """å›¾å…³ç³»é£é™© Agent èŠ‚ç‚¹"""
        payload = state["payload"]
        logger.info("="*60)
        logger.info("ğŸ¤– GraphAgent å¼€å§‹åˆ†æ...")
        logger.debug(f"è¾“å…¥ payload: {payload}")
    
        if not settings.KIMI_API_KEY:
            state["graph"] = {
                "graph_risk_level": "medium",
                "graph_reasons": ["LLM æœªå¯ç”¨, ä½¿ç”¨é»˜è®¤å›¾å…³ç³»åˆ†æç»“æœ"],
            }
            logger.warning("GraphAgent: KIMI_API_KEY æœªé…ç½®, ä½¿ç”¨é»˜è®¤ç»“æœ")
            return state
    
        system_prompt = (
            "ä½ æ˜¯é‡‘èåæ¬ºè¯ˆç³»ç»Ÿä¸­çš„'å›¾å…³ç³»é£é™©'ä¸“å®¶, "
            "è´Ÿè´£ä»è®¾å¤‡/IP/åœ°å€å…±äº«åº¦ã€ç¤¾åŒºæ¬ºè¯ˆç‡ç­‰è§’åº¦è¯„ä¼°é£é™©ã€‚"
        )
        user_prompt = (
            "ä¸‹é¢æ˜¯ä¸å½“å‰äº¤æ˜“ç›¸å…³çš„ JSON æ•°æ®(åŒ…å«æ¨¡å‹åˆåˆ¤å’Œé£é™©å› ç´ ):\n\n"
            f"{json.dumps(payload, ensure_ascii=False)}\n\n"
            "è¯·åªä»'å›¾å…³ç³»ä¸å…³è”ç½‘ç»œ'çš„è§’åº¦è¿›è¡Œåˆ†æ, ç»™å‡ºå›¾å…³ç³»é£é™©ç­‰çº§å’Œç®€è¦ç†ç”±ã€‚\n"
            "ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡º, ä¸è¦åŒ…å«å¤šä½™æ–‡å­—:\n"
            "{\n"
            '  "graph_risk_level": "high|medium|low",\n'
            '  "graph_reasons": ["åŸå› 1", "åŸå› 2"]\n'
            "}"
        )
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]
    
        logger.info(f"GraphAgent Prompt (user): {user_prompt[:200]}...")
            
        try:
            content = await self.client.chat(messages)
            logger.info(f"âœ… GraphAgent åŸå§‹å“åº”: {content}")
                
            parsed = json.loads(content)
            graph_result = {
                "graph_risk_level": str(parsed.get("graph_risk_level", "medium")),
                "graph_reasons": parsed.get("graph_reasons", []) or [],
            }
            logger.info(f"âœ… GraphAgent è§£æç»“æœ: {graph_result}")
        except Exception as e:  # noqa: BLE001
            logger.error(f"âŒ GraphAgent è°ƒç”¨æˆ–è§£æå¤±è´¥: {e}")
            graph_result = {
                "graph_risk_level": "medium",
                "graph_reasons": ["GraphAgent è¾“å‡ºå¼‚å¸¸, ä½¿ç”¨é»˜è®¤ç»“æœ"],
            }
            logger.warning(f"GraphAgent ä½¿ç”¨å…œåº•ç»“æœ: {graph_result}")
    
        state["graph"] = graph_result
        logger.info("="*60)
        return state
    
    async def _rule_agent_node(self, state: FraudState) -> FraudState:
        """è§„åˆ™ä¸åˆè§„ Agent èŠ‚ç‚¹"""
        payload = state["payload"]
        logger.info("="*60)
        logger.info("ğŸ¤– RuleAgent å¼€å§‹åˆ†æ...")
        logger.debug(f"è¾“å…¥ payload: {payload}")
    
        if not settings.KIMI_API_KEY:
            state["rule"] = {
                "rule_risk_level": "medium",
                "rule_reasons": ["LLM æœªå¯ç”¨, ä½¿ç”¨é»˜è®¤è§„åˆ™åˆ†æç»“æœ"],
            }
            logger.warning("RuleAgent: KIMI_API_KEY æœªé…ç½®, ä½¿ç”¨é»˜è®¤ç»“æœ")
            return state
    
        system_prompt = (
            "ä½ æ˜¯é‡‘èåæ¬ºè¯ˆç³»ç»Ÿä¸­çš„'è§„åˆ™ä¸åˆè§„'ä¸“å®¶, "
            "è´Ÿè´£åŸºäºå‘½ä¸­è§„åˆ™å’Œä¸šåŠ¡ç­–ç•¥è¯„ä¼°æ˜¯å¦éœ€è¦æ‹’ç»æˆ–äººå·¥å®¡æ ¸ã€‚"
        )
        user_prompt = (
            "ä¸‹é¢æ˜¯ä¸å½“å‰äº¤æ˜“ç›¸å…³çš„ JSON æ•°æ®(åŒ…å«å‘½ä¸­è§„åˆ™å’Œé£é™©å› ç´ ):\n\n"
            f"{json.dumps(payload, ensure_ascii=False)}\n\n"
            "è¯·åªä»'è§„åˆ™ä¸åˆè§„'çš„è§’åº¦è¿›è¡Œåˆ†æ, ç»™å‡ºè§„åˆ™é£é™©ç­‰çº§å’Œç®€è¦ç†ç”±ã€‚\n"
            "ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡º, ä¸è¦åŒ…å«å¤šä½™æ–‡å­—:\n"
            "{\n"
            '  "rule_risk_level": "high|medium|low",\n'
            '  "rule_reasons": ["åŸå› 1", "åŸå› 2"]\n'
            "}"
        )
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]
    
        logger.info(f"RuleAgent Prompt (user): {user_prompt[:200]}...")
            
        try:
            content = await self.client.chat(messages)
            logger.info(f"âœ… RuleAgent åŸå§‹å“åº”: {content}")
                
            parsed = json.loads(content)
            rule_result = {
                "rule_risk_level": str(parsed.get("rule_risk_level", "medium")),
                "rule_reasons": parsed.get("rule_reasons", []) or [],
            }
            logger.info(f"âœ… RuleAgent è§£æç»“æœ: {rule_result}")
        except Exception as e:  # noqa: BLE001
            logger.error(f"âŒ RuleAgent è°ƒç”¨æˆ–è§£æå¤±è´¥: {e}")
            rule_result = {
                "rule_risk_level": "medium",
                "rule_reasons": ["RuleAgent è¾“å‡ºå¼‚å¸¸, ä½¿ç”¨é»˜è®¤ç»“æœ"],
            }
            logger.warning(f"RuleAgent ä½¿ç”¨å…œåº•ç»“æœ: {rule_result}")
    
        state["rule"] = rule_result
        logger.info("="*60)
        return state
    
    async def _judge_agent_node(self, state: FraudState) -> FraudState:
        """è£å†³ Agent èŠ‚ç‚¹: ç»¼åˆå„ç»´åº¦ç»“æœç»™å‡ºæœ€ç»ˆå†³ç­–"""
        logger.info("="*60)
        logger.info("ğŸ¤– JudgeAgent å¼€å§‹ç»¼åˆè£å†³...")
        logger.info(f"å·²æœ‰åˆ†æç»“æœ - Behavior: {state.get('behavior')}")
        logger.info(f"å·²æœ‰åˆ†æç»“æœ - Graph: {state.get('graph')}")
        logger.info(f"å·²æœ‰åˆ†æç»“æœ - Rule: {state.get('rule')}")
        
        combined_payload: Dict[str, Any] = {
            "request": state["payload"].get("request", {}),
            "fast_result": state["payload"].get("fast_result", {}),
            "behavior": state.get("behavior") or {},
            "graph": state.get("graph") or {},
            "rule": state.get("rule") or {},
        }
        
        logger.debug(f"JudgeAgent ç»¼åˆè¾“å…¥: {combined_payload}")

        llm_output = await self._analyze_transaction_core(combined_payload)
        state["llm_output"] = llm_output
        
        logger.info(f"âœ… JudgeAgent æœ€ç»ˆå†³ç­–: {llm_output}")
        logger.info("="*60)
        return state

    async def _analyze_transaction_core(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """åº•å±‚ LLM è°ƒç”¨ + è§£æé€»è¾‘, è¢« LangGraph èŠ‚ç‚¹å¤ç”¨"""
        logger.info("JudgeAgent å‡†å¤‡è°ƒç”¨ LLM è¿›è¡Œç»¼åˆè£å†³...")
        
        if not self.client.api_key:
            # è¿”å›ä¸€ä¸ªå®‰å…¨çš„é»˜è®¤ç»“æœ, é¿å…çº¿ä¸Šç›´æ¥æŠ¥é”™
            logger.warning("KIMI_API_KEY æœªé…ç½®, ä½¿ç”¨é»˜è®¤ LLM åˆ†æç»“æœ")
            return {
                "llm_decision": "review",
                "llm_risk_score": 0.5,
                "llm_confidence": 0.0,
                "llm_reasons": ["LLM æœªå¯ç”¨, ä½¿ç”¨é»˜è®¤å…œåº•ç»“æœ"],
                "llm_explanation": "ç”±äºæœªé…ç½® LLM æ¥å…¥, ç³»ç»Ÿå°†è¯¥ç¬”äº¤æ˜“æ ‡è®°ä¸ºéœ€è¦äººå·¥å®¡æ ¸ã€‚",
            }

        system_prompt = (
            "ä½ æ˜¯ä¸€åé‡‘èåæ¬ºè¯ˆé£æ§ä¸“å®¶, éœ€è¦ç»¼åˆæ¨¡å‹åˆåˆ¤ç»“æœã€è¡Œä¸ºåˆ†æã€å›¾å…³ç³»åˆ†æå’Œè§„åˆ™åˆ†æ, "
            "ç»™å‡ºè¿™ç¬”äº¤æ˜“çš„æœ€ç»ˆé£é™©è¯„ä¼°å’Œå†³ç­–å»ºè®®ã€‚"
        )

        user_prompt = (
            "è¯·æ ¹æ®ä»¥ä¸‹ JSON æ•°æ®, ç»¼åˆå„ä¸ªç»´åº¦çš„åˆ†æç»“æœ, è¯„ä¼°è¯¥ç¬”äº¤æ˜“æ˜¯å¦å­˜åœ¨æ¬ºè¯ˆé£é™©, "
            "å¹¶ä¸¥æ ¼æŒ‰ç…§æŒ‡å®š JSON æ ¼å¼è¾“å‡º:\n\n"
            "{payload}\n\n"
            "è¾“å‡º JSON æ ¼å¼å¦‚ä¸‹(ä¸è¦åŒ…å«å¤šä½™æ–‡å­—):\n"
            "{{\n"
            "  \"llm_decision\": \"accept|review|reject\",\n"
            "  \"llm_risk_score\": 0.0-1.0 ä¹‹é—´çš„å°æ•°,\n"
            "  \"llm_confidence\": 0.0-1.0 ä¹‹é—´çš„å°æ•°,\n"
            "  \"llm_reasons\": [\"åŸå› 1\", \"åŸå› 2\"],\n"
            "  \"llm_explanation\": \"é¢å‘é£æ§/å®¡æ ¸å‘˜çš„è‡ªç„¶è¯­è¨€è§£é‡Š\"\n"
            "}}"
        ).format(payload=json.dumps(payload, ensure_ascii=False))

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]

        logger.info(f"JudgeAgent Prompt (user): {user_prompt[:300]}...")
        
        try:
            content = await self.client.chat(messages)
            logger.info(f"âœ… JudgeAgent åŸå§‹å“åº”: {content}")
        except Exception as e:  # noqa: BLE001
            logger.error(f"âŒ è°ƒç”¨ Kimi LLM å¤±è´¥: {e}")
            return {
                "llm_decision": "review",
                "llm_risk_score": 0.5,
                "llm_confidence": 0.0,
                "llm_reasons": ["LLM è°ƒç”¨å¤±è´¥, ä½¿ç”¨é»˜è®¤å…œåº•ç»“æœ"],
                "llm_explanation": "ç”±äº LLM è°ƒç”¨å¤±è´¥, å»ºè®®äººå·¥å®¡æ ¸æœ¬ç¬”äº¤æ˜“ã€‚",
            }

        # è§£æ LLM è¿”å›çš„ JSON
        try:
            parsed = json.loads(content)
            llm_decision = str(parsed.get("llm_decision", "review"))
            llm_risk_score = float(parsed.get("llm_risk_score", 0.5))
            llm_confidence = float(parsed.get("llm_confidence", 0.0))
            llm_reasons = parsed.get("llm_reasons", []) or []
            llm_explanation = parsed.get("llm_explanation", "")
            
            logger.info(f"âœ… JudgeAgent è§£æç»“æœ - decision: {llm_decision}, score: {llm_risk_score}, confidence: {llm_confidence}")
        except Exception as e:  # noqa: BLE001
            logger.error(f"âŒ è§£æ LLM JSON è¾“å‡ºå¤±è´¥: {e}; content={content}")
            llm_decision = "review"
            llm_risk_score = 0.5
            llm_confidence = 0.0
            llm_reasons = ["LLM è¾“å‡ºæ— æ³•è§£æ, ä½¿ç”¨é»˜è®¤å…œåº•ç»“æœ"]
            llm_explanation = "ç”±äº LLM è¾“å‡ºæ ¼å¼å¼‚å¸¸, å»ºè®®äººå·¥å®¡æ ¸æœ¬ç¬”äº¤æ˜“ã€‚"

        return {
            "llm_decision": llm_decision,
            "llm_risk_score": llm_risk_score,
            "llm_confidence": llm_confidence,
            "llm_reasons": llm_reasons,
            "llm_explanation": llm_explanation,
        }

    async def analyze_transaction(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """é’ˆå¯¹å•ç¬”äº¤æ˜“åš LLM æ·±åº¦åˆ†æã€‚

        å½“å‰é€šè¿‡ LangGraph çŠ¶æ€æœºè°ƒç”¨, åç»­å¯æ‰©å±•ä¸ºå¤š Agentã€‚

        payload å»ºè®®åŒ…å«:
        - request: åŸå§‹ FraudDetectionRequest çš„ dict
        - fast_result: fast_detect çš„ç»“æœ dict (å¯é€‰)
        """
        logger.info("\n" + "#"*80)
        logger.info("ğŸš€ å¼€å§‹ LLM+Agent å¤šç»´åº¦åˆ†æå·¥ä½œæµ")
        logger.info("#"*80)
        logger.debug(f"åˆå§‹ payload: {payload}")
        
        # ä½¿ç”¨ LangGraph çš„å¼‚æ­¥è°ƒç”¨
        result_state = await self._graph.ainvoke({"payload": payload})
        
        logger.info("\n" + "#"*80)
        logger.info("ğŸ¯ LLM+Agent å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
        logger.info(f"æœ€ç»ˆè¾“å‡º: {result_state['llm_output']}")
        logger.info("#"*80 + "\n")
        
        return result_state["llm_output"]


# å…¨å±€ LLM Agent æœåŠ¡å®ä¾‹
llm_agent_service = LlmAgentService()
